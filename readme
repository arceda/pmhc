
# model t6_8M 
# train_0 -> RNN_att con 3 apochs -> complete
# train_1 -> LINEAR con 20 apochs -> complete    -> early stopping
# train_2 -> RNN con 20 apochs -> complete
# train_3 -> RNN_att con 20 apochs -> complete   -> early stopping

# model t12_35M 
# train_4 -> LINEAR con 20 apochs -> complete    -> early stopping
# train_5 -> RNN con 20 apochs -> complete
# train_6 -> RNN_att con 20 apochs -> complete

# model t30_150M
# train_7 -> Linear con 20 epochs -> complete
# train_8 -> RNN con 20 epochs -> complete
# train_9 -> RNN_att con 20 epochs -> complete

# model t33_650M 
# train_10 -> Linear con 20 epochs -> 
# train_11 -> RNN con 20 epochs -> 
# train_12 -> RNN_att con 20 epochs -> 







############ xq no  sigmoid at end #############################

generalemtne la salida es muy pequeña, por ejempplo:
tensor([[ 0.0337,  0.0093],
        [ 0.0255,  0.0096],
        [ 0.0320,  0.0104],
        [ 0.0348,  0.0077],
        [ 0.0399,  0.0055],
        [ 0.0402,  0.0095],
        [ 0.0386,  0.0114],
        [ 0.0327,  0.0065],
        [ 0.0338,  0.0092],
        [ 0.0394,  0.0054],
        [ 0.0383,  0.0082],
        [ 0.0338,  0.0137],
        [ 0.0331,  0.0106],
        [ 0.0342,  0.0096],
        [ 0.0241,  0.0065],
        [ 0.0316,  0.0086],
        [ 0.0317,  0.0126],
        [ 0.0378,  0.0079],
        [ 0.0305,  0.0097],
        [ 0.0371,  0.0100],
        [ 0.0243,  0.0134],
        [ 0.0338,  0.0104],
        [ 0.0351,  0.0071],
        [ 0.0312,  0.0089],
        [ 0.0365,  0.0133],
        [ 0.0248,  0.0109],
        [ 0.0356,  0.0070],
        [ 0.0292,  0.0134],
        [ 0.0316,  0.0040],
        [ 0.0335,  0.0121],
        [ 0.0378,  0.0098],
        [ 0.0445,  0.0050],
        [ 0.0286,  0.0075],
        [ 0.0333,  0.0200],
        [ 0.0348,  0.0114],
        [ 0.0357,  0.0139],
        [ 0.0399,  0.0044],
        [ 0.0285,  0.0153],
        [ 0.0496, -0.0038],
        [ 0.0498, -0.0028],
        [ 0.0397,  0.0030],
        [ 0.0435, -0.0044],
        [ 0.0450,  0.0040],
        [ 0.0479,  0.0055],
        [ 0.0509,  0.0065],
        [ 0.0399, -0.0001],
        [ 0.0474,  0.0031],
        [ 0.0540, -0.0080],
        [ 0.0360,  0.0072],
        [ 0.0442,  0.0011],
        [ 0.0483, -0.0010],
        [ 0.0547, -0.0032],
        [ 0.0515,  0.0033],
        [ 0.0500,  0.0099],
        [ 0.0516,  0.0031],
        [ 0.0530,  0.0032],
        [ 0.0551,  0.0092],
        [ 0.0510,  0.0052],
        [ 0.0492,  0.0025],
        [ 0.0533, -0.0075],
        [ 0.0393,  0.0020],
        [ 0.0513,  0.0056],
        [ 0.0456,  0.0067],
        [ 0.0508, -0.0035],
        [ 0.0440,  0.0048],
        [ 0.0526,  0.0097],
        [ 0.0491, -0.0014],
        [ 0.0384, -0.0027],
        [ 0.0528,  0.0083],
        [ 0.0615, -0.0098],
        [ 0.0424,  0.0037],
        [ 0.0465,  0.0016],
        [ 0.0480, -0.0053],
        [ 0.0425, -0.0096],
        [ 0.0473, -0.0026],
        [ 0.0493, -0.0020]]

Si aplicamos softmax, no hay problema, pero si tenemos solo una neurona con sigmoid, tendríamos alggo así:

[0.0776, 0.0750, 0.0781, 0.0784, 0.0742, 0.0740, 0.0820, 0.0771, 0.0819,
0.0717, 0.0788, 0.0734, 0.0774, 0.0815, 0.0768, 0.0775, 0.0782, 0.0761,
0.0706, 0.0795, 0.0731, 0.0760, 0.0802, 0.0746, 0.0809, 0.0768, 0.0840,
0.0784, 0.0764, 0.0779, 0.0757, 0.0782, 0.0737, 0.0820, 0.0748, 0.0775,
0.0785, 0.0708, 0.0661, 0.0605, 0.0698, 0.0721, 0.0768, 0.0672, 0.0692,
0.0652, 0.0681, 0.0749, 0.0730, 0.0710, 0.0696, 0.0725, 0.0658, 0.0687,
0.0719, 0.0679, 0.0723, 0.0815, 0.0768, 0.0751, 0.0710, 0.0634, 0.0720,
0.0805, 0.0706, 0.0664, 0.0662, 0.0695, 0.0649, 0.0783, 0.0642, 0.0784,
0.0611, 0.0700, 0.0578, 0.0796]

Esto no converge y no supera el 0.5 para que llegue a la clase 1.