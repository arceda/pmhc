{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Anthem, indica los binding, no habia de necesidad de ver el threshold\n",
    "* NetMHCpan4.1 indica que el threshold es 0.5 y ya decia los bindings\n",
    "* Acme indica que > a 0.42 es el threshold\n",
    "* MixMHCpred  no da un thhreshold, pero buscar el mejor para esta BD el mejor fue de 2.73083\n",
    "* MHCflurry ,tampoco da un theshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediciont Anthem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          HLA   peptide  Label  Length  \\\n",
      "0   1  HLA-A*01:01  LFGRDLSY      1       8   \n",
      "1   2  HLA-A*01:01  TDKKTHLY      1       8   \n",
      "\n",
      "                                  mhc  \n",
      "0  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
      "1  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
      "(172580, 6)\n"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../dataset/hlab/hlab_test.csv\")\n",
    "data[\"id\"] = list(range(1, data.shape[0]+1))\n",
    "\n",
    "cols = data.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('id')))\n",
    "data = data.reindex(columns=cols)\n",
    "\n",
    "print(data.head(2))\n",
    "print(data.shape)\n",
    "\n",
    "data.to_csv(\"../dataset/hlab/hlab_test2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          HLA   peptide  Label  Length  \\\n",
      "0   1  HLA-A*01:01  LFGRDLSY      1       8   \n",
      "1   2  HLA-A*01:01  TDKKTHLY      1       8   \n",
      "2   3  HLA-A*01:01  RSDTPLIY      1       8   \n",
      "\n",
      "                                  mhc  \n",
      "0  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
      "1  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
      "2  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n"
     ]
    }
   ],
   "source": [
    "# group by peptide length (k-mer)\n",
    "data_grouped = []  # cada elemento es un dataframe. \n",
    "# Ex: data_list[0] contiene los datos de peptidos de longitud 8\n",
    "# Ex: data_list[1] contiene los datos de peptidos de longitud 9\n",
    "\n",
    "for i in range(8,15):\n",
    "    peptides = data[data['Length'] == i] \n",
    "    data_grouped.append(peptides)\n",
    "    #peptides.to_csv(str(i) + \"-mer.csv\", index=False)\n",
    "\n",
    "print(data_grouped[0].head(3)) # 8-mer peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por cada grupo k-mer, ahora separamos por el tipo de HLA\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def predict_anthem(hla, peptides):\n",
    "    # save peptides in a tmp file\n",
    "    tmp_peptide_file = open(\"temp_peptide_file.txt\", \"w\")\n",
    "    tmp_peptide_file.write(\"\\n\".join(peptides))\n",
    "    tmp_peptide_file.close()\n",
    "\n",
    "    length = str(len(peptides[0]))\n",
    "\n",
    "    # cmd for anthem\n",
    "    #python sware_b_main.py --length 9 --HLA HLA-A*01:01 --mode prediction --peptide_file test/predictpeptide.txt\n",
    "\n",
    "    cmd = \"cd Anthem; python sware_b_main.py --length \"+length+\" --HLA \"+hla+\" --mode prediction --peptide_file ../temp_peptide_file.txt\"    \n",
    "    os.system(cmd)\n",
    "    results = get_last_folder_created()    \n",
    "    files = glob.glob(\"Anthem/\" + str(results) + \"/*.txt\")\n",
    "    anthem_results = open(files[0], \"r\")\n",
    "    lines = anthem_results.readlines() \n",
    "    lines = lines[5:len(lines)-3] # remove header and bottom\n",
    "    bindings = []\n",
    "    probs = []\n",
    "    for line in lines: # procesamos cada peptido \n",
    "        tmp = line.split(\"\\t\")\n",
    "        #print(tmp)\n",
    "        peptide = tmp[3] # aqui esdta el peptido\n",
    "        binding = 1 if tmp[5].strip() == \"yes\" else 0 # aqui esta si is binding\n",
    "        prob = float(tmp[7].replace(\"\\n\", \"\").strip())\n",
    "        \n",
    "        bindings.append(binding)\n",
    "        probs.append(prob)\n",
    "        #print(peptide, binding)\n",
    "    return bindings , probs  \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# anthem genera los resultados en un folder, con esta funcion detectamos ese folder\n",
    "def get_last_folder_created():\n",
    "    folder = 'Anthem'\n",
    "    possible_folder = [] # subfolder con nombre de fechas\n",
    "    sub_folders = [name for name in os.listdir(folder) if os.path.isdir(os.path.join(folder, name))]\n",
    "    for folder in sub_folders:\n",
    "        if folder.isnumeric():\n",
    "            possible_folder.append(int(folder))\n",
    "    return max(possible_folder)\n",
    "\n",
    "  \n",
    "final_results = pd.DataFrame(columns=['id','HLA','peptide','Label','Length','mhc','anthem_pred', 'anthem_prob'])\n",
    "for df_by_kmer in data_grouped: # itereamos por cada k-mer\n",
    "    print(\"generating...\")\n",
    "    hlas = df_by_kmer['HLA'].unique()\n",
    "    for hla in hlas:\n",
    "        df_by_hla = df_by_kmer[df_by_kmer['HLA'] == hla] # dividimos por tipo de hla\n",
    "        peptides = df_by_hla[\"peptide\"].tolist()     \n",
    "        bindings, probs = predict_anthem(hla, peptides)   \n",
    "        df_by_hla[\"anthem_pred\"] = bindings\n",
    "        df_by_hla[\"anthem_prob\"] = probs\n",
    "        final_results = pd.concat([final_results, df_by_hla]) \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "#final_results.to_csv(\"results_tmp.csv\", index=False)\n",
    "print(\"finish :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = final_results.sort_values('id')\n",
    "final_results.to_csv(\"prediction_anthem.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with ESMt6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar softmax para normalizar los logits obtenidos en las predicciones de esm2t6 y tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def softmax(logits):\n",
    "    return (np.exp(logits) / np.exp(logits).sum() )\n",
    "\n",
    "#print(softmax([16.917, 0.772]))\n",
    "\n",
    "#data = pd.read_csv(\"../predictions/30epochs_esm2_t6_freeze.csv\", index_col=0)\n",
    "data = pd.read_csv(\"/M2/ArgosMHC_models/predictions/distilbert_t33_c3.csv\", index_col=0)\n",
    "data['prob_0'] = data.apply(lambda row: ( softmax([row[0], row[1]])[0] ), axis=1)\n",
    "data['prob_1'] = data.apply(lambda row: ( softmax([row[0], row[1]])[1] ), axis=1)\n",
    "data.to_csv(\"predictions_esm2_t33_distil.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"../predictions/30epochs_tape_acc_steps.csv\", index_col=0)\n",
    "data = pd.read_csv(\"/M2/ArgosMHC_models/predictions/tape_c3.csv\", index_col=0)\n",
    "data['prob_0'] = data.apply(lambda row: ( softmax([row[0], row[1]])[0] ), axis=1)\n",
    "data['prob_1'] = data.apply(lambda row: ( softmax([row[0], row[1]])[1] ), axis=1)\n",
    "data.to_csv(\"predictions_tape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1  prediction  label    prob_0    prob_1\n",
      "0 -1.515012  2.123430           1      1  0.025620  0.974380\n",
      "1 -2.883986  3.783111           1      1  0.001270  0.998730\n",
      "2 -4.096594  5.074096           1      1  0.000104  0.999896\n",
      "3 -3.912578  5.064070           1      1  0.000126  0.999874\n",
      "4 -1.187903  2.257972           1      1  0.030892  0.969108\n",
      "5  0.383407  0.175635           0      1  0.551757  0.448243\n",
      "6 -1.899285  2.613402           1      1  0.010850  0.989150\n",
      "7 -2.634839  3.608717           1      1  0.001939  0.998061\n",
      "8 -1.740799  2.500628           1      1  0.014183  0.985817\n",
      "9 -2.192737  3.056245           1      1  0.005225  0.994775\n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with MixMHCpred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MixMHCpred es una herramienta top mejor en varios reviews: A comprehensive review and performance evaluation of bioinformatics tools for HLA class I peptide-binding prediction. Ahora en la version 2.2, es mejor: https://github.com/GfellerLab/MixMHCpred/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../dataset/hlab/hlab_test2.csv\")\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "final_results = pd.DataFrame(columns=['id','HLA','peptide','Label','Length','mhc','mixmhcpred_score', 'mixmhcpred_rank'])\n",
    "\n",
    "def predict_mixmhcpred(hla,peptides):\n",
    "    # create input file for Mixmhcpred\n",
    "    inputfile = open(\"MixMHCpred/test/input.fa\", \"w\")\n",
    "    for pep in peptides:\n",
    "        inputfile.write(\"> ESNT0000_\" + pep + \"\\n\" + pep + \"\\n\")\n",
    "    inputfile.close()\n",
    "\n",
    "    # call MixMHCpred\n",
    "    cmd = \"cd MixMHCpred; ./MixMHCpred -i test/input.fa -o test/out.txt -a \" + hla    \n",
    "    os.system(cmd)\n",
    "\n",
    "    # read output\n",
    "    results = open(\"MixMHCpred/test/out.txt\", \"r\")\n",
    "    lines = results.readlines()\n",
    "    results.close()\n",
    "    data_results = lines[12:len(lines)]\n",
    "    scores = []\n",
    "    ranks = []\n",
    "    for single_result in data_results:\n",
    "        tmp = single_result.split(\"\\t\")        \n",
    "        scores.append( float(tmp[1]) ) # get score\n",
    "        ranks.append( float(tmp[3]) ) # get rank\n",
    "\n",
    "    return scores,ranks\n",
    "\n",
    "# Pra MixMHCpred, haremos las predicciones por HLA. Si le enviamos  varios hla, solo retorna con que hla hizo mejor el binding.\n",
    "hlas = data['HLA'].unique()\n",
    "for hla in hlas:\n",
    "    print(\"processing...\", hla)\n",
    "    df_by_hla = data[data['HLA'] == hla] # dividimos por tipo de hla\n",
    "    peptides = df_by_hla[\"peptide\"].tolist()     \n",
    "    scores,ranks = predict_mixmhcpred(hla, peptides)   \n",
    "    df_by_hla[\"mixmhcpred_score\"] = scores\n",
    "    df_by_hla[\"mixmhcpred_rank\"] = ranks\n",
    "    final_results = pd.concat([final_results, df_by_hla]) \n",
    "\n",
    "    \n",
    "    \n",
    "final_results = final_results.sort_values('id')\n",
    "final_results.to_csv(\"predictions_mixmhcpred.csv\", index=False)\n",
    "print(\"finish :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregamos la prediccion de MicMHCpred\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"predictions_mixmhcpred.csv\")\n",
    "threshold = 2.73083 # es el mejor threshold para MixMHCpred, fue calculado en metrics\n",
    "data['mixmhcpred_pred'] = data.apply(lambda row: ( 1 if row['mixmhcpred_rank'] < threshold else 0), axis=1)\n",
    "print(data.head())\n",
    "\n",
    "data.to_csv(\"predictions_mixmhcpred.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction MHCFLurry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two columns give the antigen processing and presentation scores, respectively. These range from 0 to 1 with higher values indicating more favorable processing or presentation.\n",
    "\n",
    "The processing predictor is experimental. It models allele-independent effects that influence whether a peptide will be detected in a mass spec experiment. The presentation score is a simple logistic regression model that combines the (log) binding affinity prediction with the processing score to give a composite prediction. The resulting prediction may be useful for prioritizing potential epitopes, but no thresholds have been established for what constitutes a “high enough” presentation score.\n",
    "\n",
    "https://openvax.github.io/mhcflurry/commandline_tutorial.html#generating-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          HLA   peptide  Label  Length  \\\n",
      "0   1  HLA-A*01:01  LFGRDLSY      1       8   \n",
      "1   2  HLA-A*01:01  TDKKTHLY      1       8   \n",
      "2   3  HLA-A*01:01  RSDTPLIY      1       8   \n",
      "\n",
      "                                  mhc  \n",
      "0  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
      "1  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
      "2  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../dataset/hlab/hlab_test2.csv\")\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "final_results = pd.DataFrame(columns=['id','HLA','peptide','Label','Length','mhc'])\n",
    "\n",
    "def predict_mhcflurry(hla,peptides):\n",
    "    print(len(peptides))\n",
    "    pep_str = \" \".join(peptides)    \n",
    "\n",
    "    # call MixMHCpred\n",
    "    cmd = \"mhcflurry-predict --alleles \" + hla + \" --peptides \" + pep_str + \" --out tmp_predictions_mhcflurry.csv \"    \n",
    "    os.system(cmd)\n",
    "\n",
    "    # read output\n",
    "    predictions = pd.read_csv(\"tmp_predictions_mhcflurry.csv\")\n",
    "\n",
    "    \n",
    "\n",
    "    return  predictions[\"mhcflurry_affinity\"], predictions[\"mhcflurry_affinity_percentile\"], predictions[\"mhcflurry_processing_score\"], predictions[\"mhcflurry_presentation_score\"], predictions[\"mhcflurry_presentation_percentile\"]\n",
    "\n",
    "# Pra MHCFlurry, haremos las predicciones por HLA. \n",
    "hlas = data['HLA'].unique()\n",
    "#print(hlas)\n",
    "for hla in hlas:\n",
    "    print(\"processing...\", hla)\n",
    "\n",
    "    #if hla != \"HLA-A*29:02\": continue\n",
    "\n",
    "\n",
    "    df_by_hla = data[data['HLA'] == hla] # dividimos por tipo de hla\n",
    "    peptides = df_by_hla[\"peptide\"].tolist()     \n",
    "    aff, aff_per, score, present, present_per  = predict_mhcflurry(hla, peptides)  \n",
    "    \n",
    "    df_by_hla[\"affinity\"] = aff.tolist() \n",
    "    df_by_hla[\"affinity_percentile\"] = aff_per.tolist() \n",
    "    df_by_hla[\"processing_score\"] = score.tolist() \n",
    "    df_by_hla[\"presentation_score\"] = present.tolist() \n",
    "    df_by_hla[\"presentation_percentile\"] = present_per.tolist() \n",
    "    print(df_by_hla.head(10)) # x motivos raros, al agregar esto se arreglo. al princpio, no copiaba la infomracion de los dataframes.\n",
    "    final_results = pd.concat([final_results, df_by_hla])   \n",
    "\n",
    "    \n",
    "    \n",
    "final_results = final_results.sort_values('id')\n",
    "final_results.to_csv(\"predictions_mhcflurry.csv\", index=False)\n",
    "print(\"finish :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23886 inf 0.0029054224539779 inf\n",
      "[0.72295951 0.72295824 0.72277737 0.72275643 0.72268608 0.72268076\n",
      " 0.72260864 0.7225967  0.72218884 0.7221867  0.72196637 0.72196445\n",
      " 0.72154094 0.72152752 0.72090448 0.72090366 0.72057499 0.7205681\n",
      " 0.72055706 0.72047599 0.72042397 0.72040619 0.72039148 0.72036535\n",
      " 0.7203087  0.72030771 0.72002765 0.71999193 0.71998104 0.7199552 ]\n",
      "best threshold 0.094388919139774\n",
      "AUC: 0.9641677983696788\n"
     ]
    }
   ],
   "source": [
    "# agregamos la prediccion de MicMHCpred\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    auc, roc_curve,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"predictions_mhcflurry.csv\")\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(data['Label'], data['presentation_score'], pos_label = 1)\n",
    "print(len(thresholds), max(thresholds), min(thresholds), sum(thresholds)/len(thresholds))\n",
    "print(thresholds[2000:2030])\n",
    "\n",
    "# IMPORTANTE, CON ESTO SABEMOS CUAL ES EL BEST THRESHOLD\n",
    "print(\"best threshold\", thresholds[np.argmax(tpr - fpr)])\n",
    "auc_val = auc(fpr, tpr)    \n",
    "print(\"AUC:\", auc_val)\n",
    "\n",
    "threshold = 0.094388919139774 # es el mejor threshold para MHCflurry\n",
    "data['mhcflurry_prob'] = data['presentation_score']\n",
    "data['mhcflurry_pred'] = data.apply(lambda row: ( 1 if row['presentation_score'] > threshold else 0), axis=1)\n",
    "#print(data.head())\n",
    "\n",
    "data.to_csv(\"predictions_mhcflurry.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
